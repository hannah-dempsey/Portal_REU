---
title: "data_cleaning"
author: "Hannah Dempsey"
output: github_document
---

# Cleaning Rodent Survey Datasets

Set up:

```{r}
library(tidyverse)
library(portalr)
```

## Saguaro National Park

Reading in the dataset:

```{r}
saguaro <- read_csv("../data_raw/saguaro_rodents.csv", skip = 5)
```

Cleaning the dataset:

```{r}
saguaro_clean <- saguaro %>% 
  rename(Trap_Check_Date = `Trap Check Date`,
         Recapture = `Recapture?`,
         Mass_g = `Mass (g)`,
         Reprod_Cond = `Reprod. Cond.`,
         Web_Trap_Number = `Web Trap #`) %>% 
  separate(Species, c("Genus", "Species"), sep = " ") %>% 
  mutate(Trap_Check_Date = dmy(Trap_Check_Date),
         Year = year(Trap_Check_Date),
         Month = month(Trap_Check_Date),
         Day = day(Trap_Check_Date),
         Recapture = toupper(Recapture),
         Recapture = str_replace(Recapture, "R", "Y"),
         Recapture = replace_na(Recapture, "N"),
         Mass_g = as.numeric(Mass_g)) %>% 
  select(Trap_Check_Date, Year, Month, Day, everything()) %>% 
  filter(Genus != is.na(Genus)) %>% 
  filter(Species != "auduboni" & Species != "harrisii") %>% 
  rename_with(tolower)

saguaro_clean
write_csv(saguaro_clean, "../data_clean/saguaro_clean.csv")
```

## Organ Pipe National Monument

Reading in the datasets:

```{r}
orpi_species_codes <- read_csv("../data_raw/tluRodentSpecies.csv")
orpi_data <- read_csv("../data_raw/RodentDetail.csv")
orpi_surveys <- read_csv("../data_raw/RodentSurvey.csv")
```

Cleaning the datasets:

```{r}
orpi_species_codes <- orpi_species_codes %>% 
  select(-5) %>% 
  rename_with(tolower) %>% 
  rename(rodent_species_id = id,
         species_code = speciescode) %>% 
  separate(genusspecies, c("genus", "species"), sep = " ")

orpi_surveys <- orpi_surveys %>% 
  rename_with(tolower) %>% 
  select(-6, -9, -11, -12, -13, -14, -15) %>% 
  rename(rodent_survey_id = id,
         site_id = siteid,
         start_date = startdate,
         end_date = enddate,
         num_traps = numtraps)

orpi_clean <- orpi_data %>% 
  rename_with(tolower) %>% 
  select(1:3, 9:10) %>%
  rename(rodent_survey_id = rodentsurveyid,
         rodent_species_id = rodentspeciesid) %>% 
  left_join(orpi_species_codes, join_by(rodent_species_id)) %>% 
  left_join(orpi_surveys, join_by(rodent_survey_id))

orpi_clean
write_csv(orpi_clean, "../data_clean/orpi_clean.csv")
write_csv(orpi_surveys, "../data_clean/orpi_surveys.csv")
```

## Portal Project

Loading in the datasets:

```{r}
#data acquired using portalr package

#abundance data, limit to control treatments
portal_abund <- abundance(effort = T, level = "Treatment", type = "Rodents", shape = "Flat")
portal_abund <- portal_abund %>% 
  filter(treatment == "control")

#loading in ancillary data
data_tables <- load_rodent_data()
species <- data_tables$species_table
trapping <- data_tables$trapping_table
plots <- data_tables$plots_table
```

Cleaning the abundance data set:

```{r}
#adding species information
#can't print out this dataset like the others (because it just goes on forever in the knit), bc not tibble??
portal_abund <- portal_abund %>% 
  left_join(species, join_by(species)) %>% 
  mutate(effort = ntraps / nplots) %>% 
  select(1:9, 18, 21) %>% 
  rename(scientific_name = scientificname,
         common_name = commonname,
         avg_weight_g = meanwgt)

#adding period dates
period_durations <- trapping %>% 
  mutate(date = make_date(year = year,
                         month = month,
                         day = day)) %>% 
  select(4:9) %>% 
  group_by(period) %>% 
  summarize(start_date = min(date),
            end_date = max(date))
period_durations

portal_abund <- portal_abund %>% 
  left_join(period_durations, join_by(period)) %>% 
  mutate(year = year(end_date),
         month = month(end_date)) %>% 
  select(14, 15, 1:11)

write_csv(portal_abund, "../data_clean/portal_abund.csv")
```
